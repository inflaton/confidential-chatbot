# LLM_MODEL_TYPE=openai
# LLM_MODEL_TYPE=gpt4all-j
LLM_MODEL_TYPE=llamacpp
# LLM_MODEL_TYPE=huggingface
# LLM_MODEL_TYPE=mosaicml
# LLM_MODEL_TYPE=other

OPENAI_API_KEY=

HUGGINGFACE_MODEL_ID="TheBloke/wizardLM-7B-HF"

# cpu or cuda - if unset, use gpu when detected
HF_EMBEDDINGS_DEVICE_TYPE=

# if unset, default to "hkunlp/instructor-xl"
HF_EMBEDDINGS_MODEL_NAME=

# number of cpu cores - used to set n_threads for GPT4ALL & LlamaCpp models
NUMBER_OF_CPU_CORES=

HUGGINGFACE_MODEL_ID="TheBloke/wizardLM-7B-HF"

MOSAICML_MODEL_ID="mosaicml/mpt-1b-redpajama-200b-dolly"

OTHER_MODEL_ID="tiiuae/falcon-rw-1b"

# https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin
GPT4ALL_J_MODEL_PATH="../../models/ggml-gpt4all-j-v1.3-groovy.bin"

# https://huggingface.co/TheBloke/wizardLM-7B-GGML/resolve/main/wizardLM-7B.ggmlv3.q4_1.bin
LLAMACPP_MODEL_PATH="../../models/wizardLM-7B.ggmlv3.q4_1.bin"

# Index for PCI DSS v4 PDF files - chunk_size=512 chunk_overlap=32
# CHROMADB_INDEX_PATH="../data/chromadb_512_32/"

# Index for PCI DSS v4 PDF files - chunk_size=1024 chunk_overlap=64
CHROMADB_INDEX_PATH="../data/chromadb_1024_64/"

# env variables for ingesting source PDF files
SOURCE_PDFS_PATH="../data/pdfs/"
SOURCE_URLS="../data/pci_dss_urls.txt"
CHUNCK_SIZE=1024
CHUNK_OVERLAP=64
