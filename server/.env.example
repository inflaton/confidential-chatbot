# LLM_MODEL_TYPE=openai
# LLM_MODEL_TYPE=gpt4all-j
LLM_MODEL_TYPE=llamacpp
# LLM_MODEL_TYPE=huggingface
# LLM_MODEL_TYPE=mosaicml

OPENAI_API_KEY=

HUGGINGFACE_MODEL_ID="TheBloke/wizardLM-7B-HF"

MOSAICML_MODEL_ID="mosaicml/mpt-1b-redpajama-200b-dolly"

# https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin
GPT4ALL_J_MODEL_PATH="../../../models/ggml-gpt4all-j-v1.3-groovy.bin"

# https://huggingface.co/TheBloke/wizardLM-7B-GGML/resolve/previous_llama_ggmlv2/wizardLM-7B.ggml.q5_1.bin
LLAMACPP_MODEL_PATH="../../../models/wizardLM-7B.ggml.q5_1.bin"

# https://huggingface.co/TheBloke/wizard-mega-13B-GGML/resolve/previous_llama_ggmlv2/wizard-mega-13B.ggml.q5_1.bin
# LLAMACPP_MODEL_PATH="../../models/wizard-mega-13B.ggml.q5_1.bin"

# https://huggingface.co/eachadea/ggml-vicuna-7b-1.1/resolve/main/ggml-vic7b-q5_1.bin
# LLAMACPP_MODEL_PATH="../../../models/ggml-vic13b-q5_1.bin"

# https://huggingface.co/TheBloke/GPT4All-13B-snoozy-GGML/blob/main/GPT4All-13B-snoozy.ggml.q5_1.bin
# LLAMACPP_MODEL_PATH="../../../models/GPT4All-13B-snoozy.ggml.q5_1.bin"

# Index for PCI DSS v4 PDF files - chunk_size=512 chunk_overlap=32
# CHROMADB_INDEX_PATH="../../data/pci_dss_v4/chromadb/"

# Index for PCI DSS v4 PDF files - chunk_size=1024 chunk_overlap=64
CHROMADB_INDEX_PATH="../../data/pci_dss_v4/chromadb_1024_64/"

# env variables for ingesting source PDF files
SOURCE_PDFS_PATH="../../data/pci_dss_v4/pdfs/"
SOURCE_URLS="../../data/pci_dss_v4/pci_dss_urls.txt"
CHUNCK_SIZE=1024
CHUNK_OVERLAP=64
